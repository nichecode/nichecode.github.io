[{"content":" This is Part 3 of a 3-part series on architecting Go applications for testability. This final part covers real-world applications, metrics, and advanced patterns. The Power of Pure Domain Logic #In Part 1, we introduced the concept of structuring applications with a pure functional core surrounded by an imperative shell. Let\u0026rsquo;s dig deeper into why this pattern is so powerful for testability:\nOur Hybrid Approach: A Testable Imperative Shell #A key innovation in our approach is how we handle the \u0026ldquo;imperative shell\u0026rdquo; portion of the Functional Core, Imperative Shell pattern. In the classic FCIS pattern, the shell contains all side effects and is typically tested primarily through integration tests.\nWhat makes our approach different is that we\u0026rsquo;ve made the imperative shell itself highly testable by:\nSplitting it into two parts:\nApplication Layer: Handles orchestration but uses interfaces to abstract external dependencies Infrastructure Layer: Implements those interfaces and manages actual I/O Using dependency inversion to allow fake implementations to be injected for testing\nflowchart TD %% Traditional FCIS Pattern subgraph subGraph0[\"Traditional FCIS\"] subgraph Shell[\"Imperative Shell\"] IS[\"Orchestration Logic\"] end subgraph Core[\"Functional Core\"] FC[\"Domain Logic\"] end subgraph External1[\"External Dependencies\"] DB1[(\"Database\")] API1{{\"API\"}} FS1[\"File System\"] end IS --\u003e FC IS --\u003e DB1 IS --\u003e API1 IS --\u003e FS1 IT[\"Integration Tests\"] -.-\u003e Shell UT1[\"Unit Tests\"] -.-\u003e Core end %% Our Testable Approach subgraph subGraph1[\"Our Testable Imperative Shell\"] %% Domain Package (independent, core logic) subgraph DomainPkg[\"domain/\"] subgraph Dom[\"Domain Layer\"] DL[\"Pure Domain Logic\"] DM[\"Domain Models\"] end end %% Application Package (defines interfaces, orchestrates) subgraph AppPkg[\"application/\"] subgraph App[\"Application Layer\"] AL[\"Application Services\"] subgraph Interfaces[\"Interfaces\"] RI[\"Repository Interface\"] LI[\"Logger Interface\"] end subgraph Contracts[\"API Contracts\"] AC[\"Request/Response Models\"] end end end %% Infrastructure Package (implementations) subgraph InfraPkg[\"infrastructure/\"] subgraph Infra[\"Infrastructure Layer\"] subgraph RealImpl[\"Real Implementations\"] CR[\"Concrete Repository\"] CL[\"Concrete Logger\"] end subgraph FakeImpl[\"Fake Implementations\"] FR[\"Fake Repository\"] FL[\"Fake Logger\"] end subgraph Handlers[\"Entry Points\"] HT[\"HTTP Handlers\"] MC[\"Message Consumers\"] end end subgraph External2[\"External Dependencies\"] DB2[(\"Database\")] API2{{\"API\"}} FS2[\"File System\"] end end %% Relationships between layers AL --\u003e RI AL --\u003e LI AL --\u003e DL AL --\u003e DM %% Infrastructure implements interfaces CR --\u003e RI CL --\u003e LI FR --\u003e RI FL --\u003e LI %% Infrastructure connects to external CR --\u003e DB2 CR --\u003e API2 CL --\u003e FS2 %% Handlers use application services HT --\u003e AL MC --\u003e AL %% Testing arrows UT2[\"Unit Tests with Fakes\"] -.-\u003e App UT3[\"Unit Tests\"] -.-\u003e Dom IT2[\"Integration Tests\"] -.-\u003e RealImpl end %% Styling classDef shellClass fill:#e0e0e0,stroke:#333,stroke-dasharray:5 5,color:black classDef coreClass fill:#b8f2d7,stroke:#333,stroke-width:2px,color:black classDef extClass fill:#fff,stroke:#333,color:black classDef testClass fill:#f8f8f8,stroke:#333,color:black,stroke-dasharray:3 3 classDef infraClass fill:#e0e0e0,stroke:#333,color:black classDef appClass fill:#a1c6ff,stroke:#333,color:black classDef domainClass fill:#b8f2d7,stroke:#333,stroke-width:2px,color:black classDef interfaceClass fill:#fff0a0,stroke:#333,color:black classDef fakeClass fill:#ffccd5,stroke:#333,color:black,stroke-dasharray:5 5 classDef noteClass fill:#f8f8f8,stroke:#333,color:black classDef mainGraphClass fill:#2d333b,stroke:#d4d4d4,stroke-width:2px,color:white classDef packageClass fill:#3f464e,stroke:#ffffff54,stroke-width:1px,color:white %% Apply styles class IS shellClass class FC coreClass class DB1,API1,FS1,DB2,API2,FS2 extClass class IT,UT1,UT2,UT3,IT2 testClass class CR,CL,HT,MC infraClass class AL,AC appClass class DL,DM domainClass class RI,LI interfaceClass class FR,FL fakeClass class subGraph0,subGraph1 mainGraphClass class DomainPkg,AppPkg,InfraPkg packageClass %% Make inner containers styled style Shell fill:#e0e0e054,stroke:#d4d4d4,stroke-dasharray:5 5 style Core fill:#b8f2d754,stroke:#d4d4d4,stroke-width:2px style Dom fill:#b8f2d754,stroke:#d4d4d4,stroke-width:2px style App fill:#a1c6ff54,stroke:#d4d4d4 style Infra fill:#e0e0e054,stroke:#d4d4d4 style RealImpl fill:#e0e0e054,stroke:#d4d4d4 style FakeImpl fill:#ffccd554,stroke:#d4d4d4,stroke-dasharray:5 5 style Handlers fill:#e0e0e054,stroke:#d4d4d4 style External1 fill:#ffffff54,stroke:#d4d4d4 style External2 fill:#ffffff54,stroke:#d4d4d4 style Interfaces fill:#fff0a054,stroke:#d4d4d4 style Contracts fill:#a1c6ff54,stroke:#d4d4d4 This approach gives us the best of both worlds: pure domain logic that\u0026rsquo;s trivially testable without mocks, and orchestration logic that can be tested without real external dependencies. This is a significant advantage over the pure FCIS pattern, while maintaining a simpler structure than traditional Hexagonal or Onion architectures.\nPure Functions: The Testing Superpower #Domain logic implemented as pure functions with immutable data types offers extraordinary testing benefits:\n// Example of pure domain logic - easy to test! package domain // Value object with immutability type User struct { ID string Name string Email string IsActive bool } // Pure function - no side effects, just input â†’ output func CanUserAccess(user User, resourceType string, resourceID string) bool { if !user.IsActive { return false } // Check specific access rules... return checkAccessRules(user, resourceType, resourceID) } // Testing is trivial: func TestCanUserAccess(t *testing.T) { inactiveUser := User{ID: \u0026#34;1\u0026#34;, Name: \u0026#34;Test\u0026#34;, IsActive: false} assert.False(t, CanUserAccess(inactiveUser, \u0026#34;document\u0026#34;, \u0026#34;123\u0026#34;)) activeUser := User{ID: \u0026#34;2\u0026#34;, Name: \u0026#34;Test\u0026#34;, IsActive: true} // More assertions... } The key characteristics that make pure domain logic easy to test:\nDeterministic behavior: Same inputs always yield same outputs No hidden inputs: All inputs are explicit parameters No side effects: No external state modification No dependencies: No mocking/stubbing required Immutability: No defensive copying needed in tests By keeping complex business rules in the domain, we minimize the imperative code in the application layer, whose primary job becomes orchestration rather than logic.\nThe Investment Argument: Is This Worth It? #A common concern about the architectural approach outlined in our series is the upfront investment required. Let\u0026rsquo;s address this with concrete evidence and reasoning.\nSimplicity vs. Architecture #Before diving into metrics, let\u0026rsquo;s address a common criticism: \u0026ldquo;Isn\u0026rsquo;t this just adding unnecessary complexity?\u0026rdquo;\nMany developers, particularly those coming from enterprise .NET backgrounds, have been burned by over-architected solutions that promised maintainability but delivered complexity. They\u0026rsquo;ve seen codebases where:\nSimple feature additions required touching a dozen files across multiple projects Dependency injection configurations grew to hundreds of lines Repositories ballooned to hundreds of methods Tests became brittle verification of implementation details rather than behavior The approach presented here deliberately aims for a \u0026ldquo;just enough\u0026rdquo; architecture that:\nMinimizes boilerplate: No complex frameworks or excessive abstractions required Follows Go idioms: Leverages interfaces and composition naturally Creates natural boundaries: The structure feels logical, not forced Pays for itself quickly: Initial investment in structure is rapidly offset by reduced testing and maintenance costs Unlike some over-engineered implementations of hexagonal architecture or clean architecture, this approach focuses on pragmatic benefits rather than architectural purity. The number of layers and interfaces is kept to the practical minimum needed to achieve clear separation of concerns.\nThe Value Proposition #When considering whether this architectural approach is worth the investment, consider these potential benefits:\nLocalized Changes: With clear boundaries between layers, changes tend to be contained within specific components, potentially making refactoring less risky.\nTesting Focus: The approach enables focused testing strategies for each layer - pure function testing for domain logic and fake-based testing for application logic.\nCode Organization: The structure provides a consistent place for different types of code, which may help in understanding where new code should be placed.\nSeparation of Concerns: By isolating domain logic from external dependencies, this approach can make it easier to reason about the business rules independently.\nTeam Collaboration: Clear boundaries can provide natural lines of responsibility for different team members or sub-teams.\nIt\u0026rsquo;s important to evaluate whether these potential benefits apply to your specific context and team. The approach may not be appropriate for every project, particularly smaller utilities or applications with minimal business logic complexity.\nComparison with Other Testing Approaches #Let\u0026rsquo;s compare our fake-based approach with alternatives:\nComparison of testing approaches: Mocks vs. Stubs vs. Fakes vs. Integration Tests Approach Pros Cons Best For Mocks/Spies Quick for simple cases; Fine-grained verification; Mature tooling Brittle (implementation-focused); Hard to maintain; Test-code coupling Verifying specific interactions when they\u0026rsquo;re part of the contract Stubs Very simple; Fast; Low maintenance Limited to canned responses; No state tracking; Limited verification Simple scenarios with fixed responses Heavy Integration High confidence in real behavior; Tests actual integrations Slow; Resource-intensive; Flaky; Complex setup Critical paths; Confirming system wiring Fakes + Functional Core State/behavior focused; Refactor-friendly; Fast; Simplifies most domain testing Initial implementation effort; Requires architectural discipline Most business applications; Systems needing maintainability When NOT to Use This Approach #This architecture may not be the optimal choice for all situations:\nVery Small Projects: For simple CLIs or utilities with minimal business logic, the architectural overhead may not provide sufficient benefits.\nShort-lived Projects: If the code will have a limited lifespan and maintenance isn\u0026rsquo;t a primary concern.\nInfrastructure-focused Code: Some types of infrastructure-heavy code (like proxies or simple data transformations) might not benefit as much from this separation.\nIn these cases, a simpler approach might be more appropriate, though aspects of the pattern (like clear interfaces) could still be valuable.\nAdvanced Pattern: Supporting Dry-Run Mode #One powerful benefit of having well-designed fakes is the ability to use them for features like dry-run mode. This provides additional ROI on the testing investment.\n// Example main.go with dry-run support import ( \u0026#34;flag\u0026#34; \u0026#34;context\u0026#34; // ...other imports ) func main() { isDryRun := flag.Bool(\u0026#34;dry-run\u0026#34;, false, \u0026#34;Execute in dry-run mode (no side effects)\u0026#34;) flag.Parse() // Configure dependencies based on mode cfg := bootstrap.Config{IsDryRun: *isDryRun} // Only connect to real DB if not in dry-run var db *sql.DB if !*isDryRun { db = setupRealDatabase() } // Use factories to select appropriate implementations repo := bootstrap.NewRepository(ctx, cfg, db) // Returns fake if dry-run logger := bootstrap.NewLogger(ctx, cfg) // Could use real logger even in dry-run service := application.NewUserService(repo, logger) // Run the application... if *isDryRun { logger.Info(ctx, \u0026#34;--- DRY RUN MODE ENABLED ---\u0026#34;) } // After operations, can inspect fake state if desired if *isDryRun { if fakeRepo, ok := repo.(*storage.FakeRepository); ok { for _, op := range fakeRepo.GetOperations() { // Log details about what would have happened logger.Info(ctx, \u0026#34;Would have performed operation\u0026#34;, \u0026#34;type\u0026#34;, op.OperationType, \u0026#34;timestamp\u0026#34;, op.Timestamp) } } } } This feature allows users to:\nPreview the effects of commands without making actual changes Debug complicated workflows safely Validate input data before committing changes It\u0026rsquo;s essentially a free bonus from the testing investment.\nMigrating Existing Codebases #Moving an existing codebase to this architecture doesn\u0026rsquo;t require a complete rewrite. Here\u0026rsquo;s a pragmatic migration approach:\nStart with Interfaces: Begin by defining interfaces for your repositories and other infrastructure dependencies.\nExtract Pure Logic: Identify business rules that can be moved to pure functions in a domain package.\nImplement Fakes: Create fake implementations alongside your real ones for testing.\nIncremental Refactoring: Apply this pattern to new features first, then gradually refactor existing code.\nBoundary Definition: Establish clear boundaries between layers, possibly using separate packages.\nRemember that imperfect progress is better than no progress. Even partial adoption of these principles can yield benefits.\nTesting Logging with Structured Analysis #Let\u0026rsquo;s look at a more sophisticated approach for structured logging verification:\nfunc TestServiceLogsCorrectStructuredData(t *testing.T) { // Arrange fakeLogger := logging_test.NewFakeLogger() service := NewReportingService(fakeLogger) // Act service.GenerateReport(\u0026#34;monthly\u0026#34;, \u0026#34;2023-04\u0026#34;) // Assert with structured analysis entries := fakeLogger.GetEntries() // Find specific structured log reportStartEntry := findLogEntry(entries, \u0026#34;info\u0026#34;, \u0026#34;Report generation started\u0026#34;) require.NotNil(t, reportStartEntry, \u0026#34;Missing expected log entry\u0026#34;) // Analyze structured fields fields := extractKeyValuePairs(reportStartEntry.Args) assert.Equal(t, \u0026#34;monthly\u0026#34;, fields[\u0026#34;report_type\u0026#34;]) assert.Equal(t, \u0026#34;2023-04\u0026#34;, fields[\u0026#34;period\u0026#34;]) // Verify sequence completionEntry := findLogEntry(entries, \u0026#34;info\u0026#34;, \u0026#34;Report generation completed\u0026#34;) require.NotNil(t, completionEntry, \u0026#34;Missing completion log\u0026#34;) // Verify completion entry was logged after start entry assert.Greater(t, indexOfEntry(entries, completionEntry), indexOfEntry(entries, reportStartEntry), \u0026#34;Completion log should come after start log\u0026#34;) } // Helper functions... This verifies both that logging occurred and that the specific contextual data was included.\nConclusion: The Path to Maintainable Go #Throughout this series, we\u0026rsquo;ve explored an architectural approach that combines:\nPure Functional Core: Business logic as pure functions with immutable data Clean Layered Architecture: Clear separation of concerns with dependency inversion Fake-Based Testing: State-focused testing that enables refactoring This approach isn\u0026rsquo;t about architectural purityâ€”it\u0026rsquo;s about practical benefits:\nIsolated domain logic that\u0026rsquo;s trivial to test Testable application layer with clear interfaces Protection from external contracts and infrastructure concerns Resilience to refactoring through state-based testing Simplified structure that avoids overengineering Go\u0026#39;s design principles make it ideal for implementing this architectural approach Go\u0026rsquo;s emphasis on simplicity and readability makes it the perfect language for this approach. By providing just enough structure to support testability without adding unnecessary complexity, we create a balance between development speed, maintainability, and reliability.\nRemember: Testing problems are usually structural problems in disguise. By addressing architecture first, testing becomes a natural extension of good design rather than a burden.\nWhether you\u0026rsquo;re building a new service or refactoring an existing one, these patterns provide a path to more maintainable, testable, and ultimately successful Go applications.\nWhat\u0026rsquo;s Next? #Consider these resources to further your understanding:\nGo\u0026rsquo;s Testing Package Documentation Mat Ryer\u0026rsquo;s \u0026ldquo;How I Write HTTP Services after Eight Years\u0026rdquo; Dave Cheney\u0026rsquo;s \u0026ldquo;Practical Go: Real World Advice for Writing Maintainable Go Programs\u0026rdquo; Share your experiences with this architectural approachâ€”I\u0026rsquo;d love to hear how it works for your team!\n","date":"10 April 2025","permalink":"/posts/architecting-for-testability-in-go/part-3/","section":"Posts","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003eThis is Part 3 of a 3-part series on architecting Go applications for testability. This final part covers real-world applications, metrics, and advanced patterns.\u003c/span\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"the-power-of-pure-domain-logic\" class=\"relative group\"\u003eThe Power of Pure Domain Logic \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#the-power-of-pure-domain-logic\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eIn \n      \n    \u003ca href=\"/posts/architecting-for-testability-in-go/part-1/\"\u003ePart 1\u003c/a\u003e, we introduced the concept of structuring applications with a pure functional core surrounded by an imperative shell. Let\u0026rsquo;s dig deeper into why this pattern is so powerful for testability:\u003c/p\u003e","title":"Architecting for Testability in Go (Part 3): Real-World Applications and Advanced Patterns"},{"content":"","date":null,"permalink":"/tags/architecture/","section":"Tags","summary":"","title":"Architecture"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/clean-code/","section":"Tags","summary":"","title":"Clean-Code"},{"content":"","date":null,"permalink":"/tags/go/","section":"Tags","summary":"","title":"Go"},{"content":"","date":null,"permalink":"/","section":"Nicholas Hammond","summary":"","title":"Nicholas Hammond"},{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/categories/software-development/","section":"Categories","summary":"","title":"Software Development"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/testing/","section":"Tags","summary":"","title":"Testing"},{"content":" This is Part 2 of a 3-part series on architecting Go applications for testability. This part provides concrete implementation details and code examples. TL;DR #This part provides practical implementation details and code examples for our testable architecture approach. We\u0026rsquo;ll cover interface definition, real implementations, fake implementations, and testing patterns, with complete code examples you can adapt for your projects.\nFrom Theory to Practice #In Part 1, we established the theoretical foundations of our approach. Now it\u0026rsquo;s time to see how these principles translate into actual Go code.\nOur implementation strategy follows these key steps:\nDefine clear interfaces in the application layer Create real implementations in the infrastructure layer Create comprehensive fake implementations for testing Write tests using these fakes Use a factory pattern to select the appropriate implementation Let\u0026rsquo;s walk through each step with concrete code examples.\nImplementation Strategy for Fake-Based Testing #In Part 1, we laid out the architectural foundations for testable Go applications. Now, let\u0026rsquo;s dive into concrete implementation details with comprehensive code examples.\n1. Define Clear Interfaces in the Application Layer #The foundation of our approach is defining interfaces in the application layer that express what the application needs, not how those needs are implemented:\npackage application import ( \u0026#34;context\u0026#34; \u0026#34;myapp/internal/domain\u0026#34; ) // Repository defines storage operations needed by the service. // Why interfaces? To decouple application logic from specific storage tech. type Repository interface { Get(ctx context.Context, id string) (domain.Entity, error) Save(ctx context.Context, entity domain.Entity) error } // Logger defines logging capabilities needed. type Logger interface { Info(ctx context.Context, msg string, args ...any) Error(ctx context.Context, msg string, args ...any) With(args ...any) Logger // For creating contextual loggers } The key insight: the application defines what it needs, not how those needs are met. This inversion of dependencies is crucial for testability.\nWhile the application layer contains imperative code that orchestrates workflows, all complex business rules and logic should be delegated to the pure functional domain layer. This keeps the application layer focused on coordination rather than complex logic.\nIt\u0026rsquo;s important to note that the infrastructure layer serves two vital roles in this architecture:\nIt implements the interfaces defined by the application layer (like Repository, Logger) It provides the entry points that invoke the application layer\u0026rsquo;s services (HTTP handlers, message consumers, CLI commands) This dual role makes the infrastructure layer the bridge between the outside world and your core application logic.\nDecoupling from External Contracts #A critical aspect of this architecture is protecting the domain from external contract dependencies:\n// application/contracts/api/request.go package api // UserActivationRequest is an API contract, owned by the application layer type UserActivationRequest struct { UserID string `json:\u0026#34;user_id\u0026#34;` Reason string `json:\u0026#34;reason,omitempty\u0026#34;` } // application/service.go package application import ( \u0026#34;myapp/internal/application/contracts/api\u0026#34; \u0026#34;myapp/internal/domain\u0026#34; ) func (s *UserService) ActivateUser(ctx context.Context, req api.UserActivationRequest) error { // Map from API contract to domain model userID := req.UserID // Get domain entity from storage entity, err := s.repo.Get(ctx, userID) if err != nil { return err } // Use domain logic to perform activation (pure function) activatedEntity := domain.ActivateUser(entity, req.Reason) // Save updated entity return s.repo.Save(ctx, activatedEntity) } // infrastructure/http/handler.go package http import ( \u0026#34;myapp/internal/application\u0026#34; \u0026#34;myapp/internal/application/contracts/api\u0026#34; ) func (h *UserHandler) ActivateUser(w http.ResponseWriter, r *http.Request) { // Parse request into API contract var req api.UserActivationRequest if err := json.NewDecoder(r.Body).Decode(\u0026amp;req); err != nil { http.Error(w, err.Error(), http.StatusBadRequest) return } // Call application service with API contract err := h.userService.ActivateUser(r.Context(), req) if err != nil { // Handle error return } // Send response w.WriteHeader(http.StatusOK) } This separation is critical because:\nDomain Purity: Domain models remain uncontaminated by API/messaging concerns (like JSON tags, validation rules) Contract Ownership: The application layer completely owns all external contracts Mapping Control: The application layer handles all translation between external contracts and domain models Package Structure Enforcement: The structure makes it impossible for external concerns to leak into the domain due to import paths Compatibility Management: API or message format changes can be handled in the application layer without affecting domain logic Domain Model Protection: Domain models are only exposed to the application layer and persistence - they never cross external boundaries or service boundaries directly Whether contracts live in internal/application/contracts/... or a shared pkg/ directory, the key principle remains: domain models never leak outside and external contracts never leak in.\n2. Create Real Implementations in the Infrastructure Layer #Now let\u0026rsquo;s implement these interfaces with concrete types:\npackage storage import ( \u0026#34;context\u0026#34; \u0026#34;database/sql\u0026#34; \u0026#34;myapp/internal/application\u0026#34; \u0026#34;myapp/internal/domain\u0026#34; ) // PostgresRepository implements application.Repository using Postgres. type PostgresRepository struct { db *sql.DB } func NewPostgresRepository(db *sql.DB) *PostgresRepository { return \u0026amp;PostgresRepository{db: db} } func (r *PostgresRepository) Get(ctx context.Context, id string) (domain.Entity, error) { // Implementation using SQL queries with the DB connection // ... return domain.Entity{}, nil } func (r *PostgresRepository) Save(ctx context.Context, entity domain.Entity) error { // Implementation using SQL queries // ... return nil } // Compile-time verification that PostgresRepository implements Repository var _ application.Repository = (*PostgresRepository)(nil) Similar implementations would exist for other interfaces like Logger with a real logging implementation.\n3. Create Comprehensive Fake Implementations #Here\u0026rsquo;s where the magic happens - creating fake implementations that are robust enough for thorough testing:\npackage storage import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;myapp/internal/application\u0026#34; \u0026#34;myapp/internal/domain\u0026#34; \u0026#34;myapp/internal/ctxkeys\u0026#34; // For context key handling \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // FakeRepository implements application.Repository for testing and dry-run. type FakeRepository struct { mu sync.RWMutex entities map[string]domain.Entity operations []OperationLog // Records all operations for verification saveErr error // For simulating errors getErr error } // OperationLog records details about calls made to the fake. type OperationLog struct { OperationType string // \u0026#34;Get\u0026#34;, \u0026#34;Save\u0026#34;, etc. Params OperationParams Timestamp time.Time CorrelationID string // Example of capturing context data } // OperationParams uses a union-like approach for type safety. type OperationParams struct { GetParams *GetParams // Only one of these will be non-nil SaveParams *SaveParams // depending on operation type } type GetParams struct { ID string } type SaveParams struct { Entity domain.Entity } func NewFakeRepository() *FakeRepository { return \u0026amp;FakeRepository{ entities: make(map[string]domain.Entity), operations: make([]OperationLog, 0), } } // Get implements the Repository interface func (f *FakeRepository) Get(ctx context.Context, id string) (domain.Entity, error) { f.mu.Lock() defer f.mu.Unlock() // Extract correlation ID from context as an example corrID := ctxkeys.GetCorrelationID(ctx) // Record this operation f.operations = append(f.operations, OperationLog{ OperationType: \u0026#34;Get\u0026#34;, Params: OperationParams{ GetParams: \u0026amp;GetParams{ID: id}, }, Timestamp: time.Now(), CorrelationID: corrID, }) // Simulate error if configured if f.getErr != nil { return domain.Entity{}, f.getErr } // Otherwise return the entity from the in-memory map entity, ok := f.entities[id] if !ok { return domain.Entity{}, fmt.Errorf(\u0026#34;entity %s not found\u0026#34;, id) } return entity, nil } // Save implements the Repository interface func (f *FakeRepository) Save(ctx context.Context, entity domain.Entity) error { f.mu.Lock() defer f.mu.Unlock() corrID := ctxkeys.GetCorrelationID(ctx) f.operations = append(f.operations, OperationLog{ OperationType: \u0026#34;Save\u0026#34;, Params: OperationParams{ SaveParams: \u0026amp;SaveParams{Entity: entity}, }, Timestamp: time.Now(), CorrelationID: corrID, }) if f.saveErr != nil { return f.saveErr } f.entities[entity.ID] = entity return nil } // Test Helper Methods (for convenient test setup and verification) func (f *FakeRepository) WithEntities(entities ...domain.Entity) *FakeRepository { f.mu.Lock() defer f.mu.Unlock() for _, e := range entities { f.entities[e.ID] = e } return f } func (f *FakeRepository) SimulateGetError(err error) *FakeRepository { f.mu.Lock() defer f.mu.Unlock() f.getErr = err return f } func (f *FakeRepository) SimulateSaveError(err error) *FakeRepository { f.mu.Lock() defer f.mu.Unlock() f.saveErr = err return f } func (f *FakeRepository) GetOperations() []OperationLog { f.mu.RLock() defer f.mu.RUnlock() // Return a copy to prevent modification issues opsCopy := make([]OperationLog, len(f.operations)) copy(opsCopy, f.operations) return opsCopy } // Ensure the fake implements the interface var _ application.Repository = (*FakeRepository)(nil) This FakeRepository is comprehensive:\nIt maintains state in memory (the entities map) It records all operations for verification It can be configured to simulate errors It includes helper methods for test setup It handles thread safety with mutex locks Similarly, we can implement a fake logger:\npackage logging_test import ( \u0026#34;context\u0026#34; \u0026#34;myapp/internal/application\u0026#34; \u0026#34;sync\u0026#34; ) // LogEntry captures details of a log call. type LogEntry struct { Level string Message string Args []any } // FakeLogger implements application.Logger for testing. type FakeLogger struct { mu sync.RWMutex entries []LogEntry } func NewFakeLogger() *FakeLogger { return \u0026amp;FakeLogger{entries: make([]LogEntry, 0)} } func (f *FakeLogger) Info(ctx context.Context, msg string, args ...any) { f.log(\u0026#34;info\u0026#34;, msg, args) } func (f *FakeLogger) Error(ctx context.Context, msg string, args ...any) { f.log(\u0026#34;error\u0026#34;, msg, args) } func (f *FakeLogger) With(args ...any) application.Logger { // For simplicity, this example just returns self // A more sophisticated fake might track these args return f } func (f *FakeLogger) log(level string, msg string, args []any) { f.mu.Lock() defer f.mu.Unlock() // Copy args to prevent modification issues argsCopy := make([]any, len(args)) copy(argsCopy, args) f.entries = append(f.entries, LogEntry{ Level: level, Message: msg, Args: argsCopy, }) } // Helper methods for tests func (f *FakeLogger) Count() int { f.mu.RLock() defer f.mu.RUnlock() return len(f.entries) } func (f *FakeLogger) GetEntries() []LogEntry { f.mu.RLock() defer f.mu.RUnlock() // Return a copy entriesCopy := make([]LogEntry, len(f.entries)) copy(entriesCopy, f.entries) return entriesCopy } func (f *FakeLogger) ContainsMessage(substr string) bool { f.mu.RLock() defer f.mu.RUnlock() for _, entry := range f.entries { if strings.Contains(entry.Message, substr) { return true } } return false } var _ application.Logger = (*FakeLogger)(nil) 4. Where Should Fake Implementations Live? #The placement of fake implementations depends on their purpose:\nFor testing only: Place in *_test.go files within the package of the real implementation For testing AND features (like dry-run mode): Place in regular .go files This ensures that test-only code doesn\u0026rsquo;t bloat your production binary.\nTesting Philosophy: When using fakes, our tests verify state and behavior outcomes rather than implementation details. This is fundamentally different from mock-based testing, which often focuses on verifying specific method calls were made in a specific order. 5. Writing Tests with Fakes #Now that we have our fakes, let\u0026rsquo;s see how to write tests with them:\npackage application_test import ( \u0026#34;context\u0026#34; \u0026#34;errors\u0026#34; \u0026#34;myapp/internal/application\u0026#34; \u0026#34;myapp/internal/domain\u0026#34; \u0026#34;myapp/internal/ctxkeys\u0026#34; \u0026#34;myapp/internal/infrastructure/storage\u0026#34; \u0026#34;myapp/internal/infrastructure/logging_test\u0026#34; // Import fake logger \u0026#34;testing\u0026#34; \u0026#34;github.com/stretchr/testify/assert\u0026#34; \u0026#34;github.com/stretchr/testify/require\u0026#34; ) func TestUserService_ActivateUser_Success(t *testing.T) { // Arrange: Setup fakes with desired state ctx := context.WithValue(context.Background(), ctxkeys.CorrelationIDKey, \u0026#34;test-corr-id-123\u0026#34;) initialEntity := domain.Entity{ID: \u0026#34;user1\u0026#34;, IsActive: false, Name: \u0026#34;Test User\u0026#34;} fakeRepo := storage.NewFakeRepository().WithEntities(initialEntity) fakeLogger := logging_test.NewFakeLogger() service := application.NewUserService(fakeRepo, fakeLogger) userIDToActivate := \u0026#34;user1\u0026#34; // Act: Execute the application logic err := service.ActivateUser(ctx, userIDToActivate) // Assert: Verify outcome via fake state require.NoError(t, err) // Verify state change in Repository updatedEntity, getErr := fakeRepo.Get(ctx, userIDToActivate) require.NoError(t, getErr) assert.True(t, updatedEntity.IsActive, \u0026#34;Entity should be active\u0026#34;) assert.Equal(t, initialEntity.Name, updatedEntity.Name, \u0026#34;Other fields should be unchanged\u0026#34;) // Verify operations were recorded ops := fakeRepo.GetOperations() require.Len(t, ops, 2, \u0026#34;Expected Get and Save operations\u0026#34;) // Verify logging occurred assert.GreaterOrEqual(t, fakeLogger.Count(), 1, \u0026#34;Should have logged at least one message\u0026#34;) assert.True(t, fakeLogger.ContainsMessage(\u0026#34;User activated\u0026#34;), \u0026#34;Expected activation message\u0026#34;) } func TestUserService_ActivateUser_RepoError(t *testing.T) { // Arrange ctx := context.Background() repoErr := errors.New(\u0026#34;db connection lost\u0026#34;) fakeRepo := storage.NewFakeRepository(). WithEntities(domain.Entity{ID: \u0026#34;user1\u0026#34;, IsActive: false}). SimulateSaveError(repoErr) // Configure fake to simulate error fakeLogger := logging_test.NewFakeLogger() service := application.NewUserService(fakeRepo, fakeLogger) // Act err := service.ActivateUser(ctx, \u0026#34;user1\u0026#34;) // Assert require.Error(t, err) assert.ErrorIs(t, err, repoErr) // Verify error was logged assert.True(t, fakeLogger.ContainsMessage(\u0026#34;Failed to save\u0026#34;), \u0026#34;Error should have been logged\u0026#34;) } The key differences from traditional mock-based tests:\nState-based verification: We check the outcome (entity is now active) rather than implementation details Fluent configuration: Fakes have builder-style methods for easy setup Resilience to refactoring: The test doesn\u0026rsquo;t break if internal implementation changes Realistic behavior: Fakes implement the same interface as real components Testing Logging with Fakes #Testing logging is often overlooked, but it\u0026rsquo;s a crucial part of application behavior, especially for diagnostics and audit trails. Our FakeLogger makes this straightforward:\nfunc TestLoggingBehavior(t *testing.T) { // Arrange fakeLogger := logging_test.NewFakeLogger() service := NewServiceThatLogs(fakeLogger) // Act service.DoSomethingImportant(\u0026#34;test-value\u0026#34;) // Assert entries := fakeLogger.GetEntries() // Find specific log messages found := false for _, entry := range entries { if entry.Level == \u0026#34;info\u0026#34; \u0026amp;\u0026amp; entry.Message == \u0026#34;Operation started\u0026#34; { found = true // Check args contain our value for i := 0; i \u0026lt; len(entry.Args); i += 2 { if i+1 \u0026lt; len(entry.Args) \u0026amp;\u0026amp; entry.Args[i] == \u0026#34;input\u0026#34; \u0026amp;\u0026amp; entry.Args[i+1] == \u0026#34;test-value\u0026#34; { return // Test passes } } } } t.Fatalf(\u0026#34;Expected log message not found or missing expected arguments\u0026#34;) } This verifies both that logging occurred and that the specific contextual data was included.\nFactory Pattern for Implementation Selection #To manage which implementation (real or fake) is used, we can use a factory pattern:\npackage bootstrap import ( \u0026#34;context\u0026#34; \u0026#34;database/sql\u0026#34; \u0026#34;myapp/internal/application\u0026#34; \u0026#34;myapp/internal/infrastructure/storage\u0026#34; ) type Config struct { IsDryRun bool // Other config fields } // NewRepository creates a repository based on configuration. func NewRepository(ctx context.Context, cfg Config, db *sql.DB) application.Repository { if cfg.IsDryRun { return storage.NewFakeRepository() } return storage.NewPostgresRepository(db) } // Similar factories for Logger, Notifier, etc. This enables features like dry-run mode while keeping the selection logic isolated.\nTest Classification Strategy #With this architecture, we can employ a balanced testing strategy:\nUnit Tests (~85-90%)\nDomain Logic Tests: Test pure business logic directly Service Tests (with Fakes): Test application service orchestration Handler Tests (with Fake Services): Test HTTP/messaging handlers Integration Tests (~5-10%)\nTest real infrastructure components against real dependencies Focused on critical interfaces between components End-to-End Tests (~1-2%)\nTest complete user journeys through the system Fewer, focused on key scenarios Directory Structure for Tests #Organizing tests logically helps maintainability:\ninternal/ â”œâ”€â”€ application/ â”‚ â”œâ”€â”€ service.go â”‚ â”œâ”€â”€ service_test.go # Service Tests (using fakes) â”‚ â””â”€â”€ interfaces.go â”œâ”€â”€ domain/ â”‚ â”œâ”€â”€ model.go â”‚ â””â”€â”€ model_test.go # Domain Unit Tests â””â”€â”€ infrastructure/ â”œâ”€â”€ http/ â”‚ â”œâ”€â”€ handler.go â”‚ â””â”€â”€ handler_test.go # Handler Unit Tests â”œâ”€â”€ logging/ â”‚ â”œâ”€â”€ logger.go â”‚ â””â”€â”€ fake_logger_test.go # Fake Logger for tests â””â”€â”€ storage/ â”œâ”€â”€ postgres_repository.go â”œâ”€â”€ fake_repository.go # OR fake_repository_test.go â””â”€â”€ postgres_repository_integration_test.go test/ â””â”€â”€ integration/ # Broader integration tests â”œâ”€â”€ setup/ # Test setup utilities â””â”€â”€ api_test.go # Full slice tests Recommended placement:\nDomain tests: In the domain package Service tests: In application_test package -Handler tests: In infrastructure/http_test package Fake implementations: In *_test.go files or regular .go files if used for features Integration tests: In a separate test/ directory or with build tags Coming Up in Part 3 #In the final part of this series, we\u0026rsquo;ll explore:\nThe value proposition of this architectural approach Comparison with other testing methodologies Advanced patterns like dry-run mode Migration strategies for existing codebases When this approach might not be appropriate Continue reading Part 3: Real-World Applications and Advanced Patterns\n","date":"10 April 2025","permalink":"/posts/architecting-for-testability-in-go/part-2/","section":"Posts","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003eThis is Part 2 of a 3-part series on architecting Go applications for testability. This part provides concrete implementation details and code examples.\u003c/span\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"tldr\" class=\"relative group\"\u003eTL;DR \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#tldr\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eThis part provides practical implementation details and code examples for our testable architecture approach. We\u0026rsquo;ll cover interface definition, real implementations, fake implementations, and testing patterns, with complete code examples you can adapt for your projects.\u003c/p\u003e","title":"Architecting for Testability in Go (Part 2): Implementation Strategy and Code Examples"},{"content":" This is Part 1 of a 3-part series on architecting Go applications for testability. This part covers the foundational principles and architectural approach. Introduction #How easily can you understand a piece of code seconds after looking at it? How quickly can you write a meaningful test for it?\nFor many engineering teams, the answer is often \u0026ldquo;not easily enough.\u0026rdquo; Complex structures lead to high cognitive load, difficult reasoning, and consequently, tests that are brittle, slow, or hard to write â€“ making refactoring daunting and slowing down development.\nWhen tests are painful to write or maintain, it\u0026rsquo;s usually a symptom of underlying architectural issues. Well-structured applications with clear separation of concerns naturally lend themselves to straightforward, \u0026ldquo;boring\u0026rdquo; tests â€“ and boring tests are good tests.\nRelationship to Established Architectural Patterns #The approach described in this series builds upon established architectural patterns, but creates a pragmatic hybrid that addresses specific testing challenges:\nFunctional Core, Imperative Shell (FCIS): This pattern, popularized by Gary Bernhardt, emphasizes pure functions for business logic and relegates side effects to the outer \u0026ldquo;shell.\u0026rdquo; How we apply it: We strictly enforce a pure functional domain with immutable types and no side effects. However, in pure FCIS, the imperative shell can be difficult to test since it contains all side effects. Our approach makes the shell testable by dividing it into an application layer (with abstractions for external dependencies) and infrastructure layer (with implementations), enabling easier testing through fakes. Hexagonal/Onion Architecture: Both patterns focus on dependency inversion where domain logic is independent of external concerns, with dependencies pointing inward through abstractions. How we apply it: From experience, implementations of these patterns often become over-engineered with excessive abstraction layers. Our approach applies the core principles (separation of concerns, dependency inversion) while deliberately minimizing the number of layers and abstractions to what\u0026rsquo;s essential for testability. Domain-Driven Design (DDD): While not requiring full DDD adoption, our approach embraces the separation of domain logic and the use of a ubiquitous language within bounded contexts.\nHow we apply it: We focus on the tactical patterns that improve testability, particularly pure functions and immutable value objects and entities in our domain layer. The architecture described here isn\u0026rsquo;t claiming to be novelâ€”rather, it\u0026rsquo;s a practical synthesis of these proven patterns, creating a testing-friendly approach that maintains the benefits of each while avoiding common pitfalls like over-abstraction and excessive complexity.\nHow This Approach Differs From Traditional Onion Architecture #While the architecture we\u0026rsquo;ll describe in this article shares principles with Hexagonal/Onion architecture, there are important differences you\u0026rsquo;ll see as we explore it in detail:\nDeliberate Minimalism: Unlike many onion architecture implementations that introduce numerous layers and abstractions, our approach deliberately uses only three primary layers with minimal interfaces.\nFunctional Core Integration: We combine the dependency inversion of onion architecture with the pure functional approach of Functional Core, Imperative Shell - creating a stronger emphasis on immutability and side-effect isolation than typical onion architectures.\nGo-Idiomatic Implementation: Rather than forcing object-oriented patterns into Go, we leverage Go\u0026rsquo;s structural typing and composition to achieve clean architecture principles without the ceremony.\nPractical Over Pure: We prioritize practical testability and development speed over architectural purity, avoiding the \u0026ldquo;explosion of interfaces\u0026rdquo; that often plagues onion architecture implementations.\nTesting Strategy Integration: Our fake-based testing approach is integral to the architecture, not just a testing technique applied afterward.\nThis approach isn\u0026rsquo;t claiming to reinvent architecture - it\u0026rsquo;s a deliberate simplification and adaptation of established patterns with a focus on what actually matters: testable, maintainable code that\u0026rsquo;s quick to develop.\nAs we explore this architecture in more depth in the following sections, these differences will become more apparent.\nSimplicity as a Goal #A common criticism of patterns like Hexagonal/Onion Architectureâ€”especially in the .NET ecosystemâ€”is that they introduce unnecessary complexity and over-engineering. Many developers have experienced codebases where these patterns were applied dogmatically, resulting in:\nExplosion of Interfaces: One interface per class, often with only a single implementation Deep Inheritance Hierarchies: Abstractions built on abstractions Bloated Projects: Simple features requiring changes across numerous files and projects Development Friction: Taking disproportionate time to implement straightforward functionality Testing Complexity: Tests that focus more on verifying implementation details than behavior This series aims to counter these experiences by presenting:\nA Minimalist Implementation: We focus on the essential structural elements that deliver the most value, avoiding ceremonial abstractions.\nPragmatic Boundaries: Clear but not overly rigid separation of concerns, with just enough structure to enable testability and maintainability.\nGo-Idiomatic Approach: Leveraging Go\u0026rsquo;s simplicity and structural typing rather than forcing patterns from other languages.\nEmbracing Go\u0026rsquo;s Philosophy: Go was designed to be simple and approachable. The language itself discourages over-engineering through its lack of inheritance, straightforward type system, and emphasis on clarity over cleverness. Our approach aligns with this philosophy by favoring direct, readable code over complex abstractions.\nThe goal is to achieve a \u0026ldquo;Goldilocks architecture\u0026rdquo; â€“ not too complex, not too simplistic â€“ that provides the benefits of clean separation without drowning in abstraction. The ultimate measure of success is whether the architecture makes your codebase easier to understand, test, and change over time.\nThe Problem with Traditional Testing Approaches #Before diving into solutions, let\u0026rsquo;s understand some challenges that can arise with common testing approaches:\nMocks: Implementation Coupling #Testing with mocking frameworks often focuses on verifying interactions (\u0026ldquo;was method X called with argument Y?\u0026rdquo;). This approach can have several drawbacks:\nPotential Test Brittleness: Tests may break during refactoring, even when behavior is unchanged, if they\u0026rsquo;re tied to implementation details. Implementation Coupling: Tests might resist changes to internal implementation details, potentially hindering refactoring. Setup Complexity: Mock setup and expectation management can become verbose and might obscure the test\u0026rsquo;s intent. // Example of a mock-based test func TestServiceWithMocks(t *testing.T) { mockRepo := new(MockRepository) mockRepo.On(\u0026#34;Get\u0026#34;, \u0026#34;user1\u0026#34;).Return(user, nil) mockRepo.On(\u0026#34;Save\u0026#34;, mock.MatchedBy(func(u User) bool { return u.ID == \u0026#34;user1\u0026#34; \u0026amp;\u0026amp; u.IsActive == true })).Return(nil) service := NewUserService(mockRepo) err := service.ActivateUser(\u0026#34;user1\u0026#34;) require.NoError(t, err) mockRepo.AssertExpectations(t) // This verifies the implementation details } Integration Tests: Trade-offs #Relying primarily on integration tests with real dependencies brings different considerations:\nExecution Time: Tests involving databases, file systems, or network calls typically take longer to run. Resource Requirements: May require additional infrastructure setup for CI/CD environments. Environmental Factors: Tests might be affected by external conditions. The Clean Architecture Structure: Functional Core, Imperative Shell #A clean, layered architecture separates your application into distinct areas of responsibility, closely following the \u0026ldquo;Functional Core, Imperative Shell\u0026rdquo; pattern:\ninternal/ â”œâ”€â”€ domain/ # Pure business logic and types (Functional Core) â”œâ”€â”€ application/ # Orchestration \u0026amp; interface definitions (Imperative Shell) â”‚ â”œâ”€â”€ contracts/ # DTOs defining application boundaries â”‚ â”‚ â”œâ”€â”€ api/ # e.g., ActivateUserRequest, UserResponse â”‚ â”‚ â””â”€â”€ messaging/ # e.g., UserActivatedEvent â”‚ â”œâ”€â”€ interfaces.go # Interfaces defining infrastructure dependencies â”‚ â””â”€â”€ service.go # Orchestrates domain logic using interfaces, â”‚ # translates between contracts and domain models â””â”€â”€ infrastructure/ # Implementations \u0026amp; entry points (Imperative Shell) â”œâ”€â”€ bootstrap/ # Wires dependencies together â”œâ”€â”€ http/ # HTTP handlers (use application/contracts/api) â”œâ”€â”€ messaging/ # Message handlers (use application/contracts/messaging) â””â”€â”€ storage/ # Real \u0026amp; fake repository implementations With this structure:\nDomain Layer (Functional Core):\nContains pure business logic with no dependencies Uses immutable data types and value objects Consists of pure functions with no side effects All operations are deterministic and return new values rather than modifying state Easy to test in complete isolation Important: Domain models are only used by domain and application layers - they never leak to external interfaces (APIs, messaging) or cross service boundaries Application Layer (Begins the Imperative Shell):\nOrchestrates use cases by combining domain logic with external effects Defines interfaces for what it needs from the outside world Manages workflow and translates between domain and external concerns Owns all contract definitions (API DTOs, message schemas) through which the outside world interacts with the system Performs mapping between domain models and external contracts to prevent domain leakage Infrastructure Layer (Completes the Imperative Shell):\nHandles all side effects (database, network, etc.) Provides entry points into the application via APIs, message consumers, CLI commands, etc. Implements interfaces defined by the application layer Contains adapters for external systems and frameworks Translates between external formats (HTTP, message queues) and application contracts Never directly exposes domain models to the outside world Why Architect This Way? #This architectural approach offers several key benefits:\nReasoning About Code: Clear boundaries make it easier to understand what each part of the system does. Pure Domain Logic: By keeping domain logic pure (no side effects, immutable data types), we gain deterministic behavior that\u0026rsquo;s trivial to test in isolation. Testability at All Levels: Domain logic tests become simple input/output verifications Application logic can be tested with fakes for external dependencies Infrastructure components can be tested independently Flexibility: Implementation details can change without affecting the core. Maintainability: Changes tend to be localized to specific layers. Explicit Side Effects: By pushing all side effects to the outer layers, we make them explicit and easier to manage. What Are Fake Implementations? #A \u0026ldquo;Fake\u0026rdquo; in this context is a lightweight, in-memory implementation of an interface used specifically for testing:\nA working implementation that maintains its own state (e.g., data in a map) Records operations for verification purposes Can be configured to simulate specific scenarios, including errors Unlike traditional mocks which focus on interaction verification, fakes allow tests to verify the outcome of operations (state), making them more resilient to refactoring.\n// Simple example of a fake repository type FakeRepository struct { entities map[string]Entity operations []string } func (f *FakeRepository) Get(id string) (Entity, error) { f.operations = append(f.operations, \u0026#34;Get:\u0026#34;+id) entity, exists := f.entities[id] if !exists { return Entity{}, errors.New(\u0026#34;not found\u0026#34;) } return entity, nil } func (f *FakeRepository) Save(entity Entity) error { f.operations = append(f.operations, \u0026#34;Save:\u0026#34;+entity.ID) f.entities[entity.ID] = entity return nil } Coming Up in Part 2 #In the next part of this series, we\u0026rsquo;ll dive into practical implementation details with comprehensive code examples:\nDefining clear interfaces in the application layer Creating real and fake implementations Testing strategies using fakes Practical code examples Continue reading Part 2: Implementation Strategy and Code Examples\n","date":"10 April 2025","permalink":"/posts/architecting-for-testability-in-go/part-1/","section":"Posts","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003eThis is Part 1 of a 3-part series on architecting Go applications for testability. This part covers the foundational principles and architectural approach.\u003c/span\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"introduction\" class=\"relative group\"\u003eIntroduction \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#introduction\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eHow easily can you understand a piece of code seconds after looking at it? How quickly can you write a meaningful test for it?\u003c/p\u003e","title":"Architecting for Testability in Go (Part 1): Foundations and Principles"},{"content":" This is a 3-part series exploring how to architect Go applications for testability using a clean architecture approach with fake implementations instead of traditional mocks. TL;DR #Testing problems are often symptoms of architectural issues. This series presents a pragmatic approach that combines a pure functional core with a testable imperative shell, using \u0026ldquo;fake\u0026rdquo; implementations rather than traditional mocks. The result: more maintainable, easier-to-test Go applications that support refactoring without test breakage.\nThe Problem: Why Testing Go Applications Can Be Challenging #Many Go codebases suffer from:\nBrittle tests that break whenever implementation details change Slow test suites that require database connections or external services Complex mocking setups that are difficult to maintain Poor separation of concerns making unit tests challenging to write Testing difficulties are often symptoms of underlying architectural issues. When an application has clear separation of concerns and well-defined boundaries, testing becomes simpler and more effective.\nOur Solution: Clean Architecture with Fakes #This series explores a pragmatic architectural approach for Go applications that makes testing straightforward through the use of \u0026ldquo;fake\u0026rdquo; implementations.\nClean Architecture with Functional Core, Imperative Shell approach Comparison of testing approaches: Mocks vs. Stubs vs. Fakes vs. Integration Tests What You\u0026rsquo;ll Learn in This Series # Part 1: Foundations and Principles - Understanding the architectural approach and why fakes are better than mocks Part 2: Implementation Strategy and Code Examples - Detailed code examples for implementing this architecture Part 3: Real-World Applications and Advanced Patterns - Practical applications, metrics, and advanced techniques Key Benefits of This Approach #This architectural approach offers numerous advantages:\nMore robust tests - Verify behavior rather than implementation details, making tests resilient to refactoring Easier refactoring - Change implementation without breaking tests that focus on outcomes Faster feedback cycles - Run quick, reliable tests without external dependencies Cleaner test code - Write straightforward tests without complex mocking frameworks Better separation of concerns - Organize code logically by responsibility Balanced testing strategy enabled by this architecture Who This Series Is For #This series is ideal for Go developers who:\nWant to improve their application\u0026rsquo;s testability Are frustrated with brittle, hard-to-maintain tests Need to balance thorough testing with development speed Are interested in clean architecture principles applied to Go Whether you\u0026rsquo;re building a new application or refactoring an existing one, these principles can help you create more maintainable and testable Go code.\nReading Guide #Each part builds on the previous, but can also be read independently:\nStart with Part 1 if you\u0026rsquo;re new to clean architecture or want to understand the \u0026ldquo;why\u0026rdquo; Jump to Part 2 if you\u0026rsquo;re looking for concrete code examples to implement Check out Part 3 for advanced patterns and real-world applications Ready to dive in? Start with Part 1: Foundations and Principles\n","date":null,"permalink":"/posts/architecting-for-testability-in-go/","section":"Posts","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003eThis is a 3-part series exploring how to architect Go applications for testability using a clean architecture approach with fake implementations instead of traditional mocks.\u003c/span\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"tldr\" class=\"relative group\"\u003eTL;DR \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#tldr\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eTesting problems are often symptoms of architectural issues. This series presents a pragmatic approach that combines a pure functional core with a testable imperative shell, using \u0026ldquo;fake\u0026rdquo; implementations rather than traditional mocks. The result: more maintainable, easier-to-test Go applications that support refactoring without test breakage.\u003c/p\u003e","title":"Architecting for Testability in Go: Using Fakes, Not Mocks"},{"content":"","date":null,"permalink":"/tags/best-practices/","section":"Tags","summary":"","title":"Best Practices"},{"content":"Who I Am #I\u0026rsquo;m a strategic engineering leader passionate about building high-performance technical platforms and empowering engineering teams. My journey spans multiple domains, driven by a commitment to innovation and technical excellence.\nProfessional Lens #With over two decades of experience, I specialise in:\nCloud-native architectures across major cloud providers Distributed systems and microservices design Engineering leadership and team transformation Multi-cloud platform engineering\nTechnical Philosophy # I believe in building systems that are not just functional, but are also maintainable, scalable, and a joy to work with. Areas of Expertise #My technical toolkit includes:\nLanguages: Golang, C#, Python Cloud Platforms: AWS, GCP, Azure Technologies: Kubernetes, Terraform, Microservices Methodologies: Domain-Driven Design, GitOps, Event-Driven Architecture Professional Interests # Distributed Systems Cloud-Native Technologies Artificial Intelligence System Reliability Engineering FinOps and Cost Optimisation Beyond the Code #When I\u0026rsquo;m not architecting systems or leading teams, I\u0026rsquo;m exploring:\nEmerging technology trends Cloud-native innovations The intersection of technology and strategic leadership Let\u0026rsquo;s Connect #This blog is my space to share insights, challenges, and learnings from my journey in technology leadership. Whether you\u0026rsquo;re a fellow engineer, a technology enthusiast, or simply curious about modern software engineering, I hope you\u0026rsquo;ll find something valuable here.\nFeel free to reach out and connect.\nConnect With Me # GitHub LinkedIn Twitter\n","date":"9 April 2025","permalink":"/about/","section":"Nicholas Hammond","summary":"\u003ch2 id=\"who-i-am\" class=\"relative group\"\u003eWho I Am \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#who-i-am\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eI\u0026rsquo;m a strategic engineering leader passionate about building high-performance technical platforms and empowering engineering teams. My journey spans multiple domains, driven by a commitment to innovation and technical excellence.\u003c/p\u003e\n\u003ch2 id=\"professional-lens\" class=\"relative group\"\u003eProfessional Lens \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#professional-lens\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eWith over two decades of experience, I specialise in:\u003c/p\u003e\n\u003cp\u003e\n\n  \u003cspan class=\"icon relative inline-block align-text-bottom\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\n  \u003cpath d=\"M352 256c0 22.2-1.2 43.6-3.3 64H163.3c-2.2-20.4-3.3-41.8-3.3-64s1.2-43.6 3.3-64H348.7c2.2 20.4 3.3 41.8 3.3 64zm28.8-64H503.9c5.3 20.5 8.1 41.9 8.1 64s-2.8 43.5-8.1 64H380.8c2.1-20.6 3.2-42 3.2-64s-1.1-43.4-3.2-64zm112.6-32H376.7c-10-63.9-29.8-117.4-55.3-151.6c78.3 20.7 142 77.5 171.9 151.6zm-149.1 0H167.7c6.1-36.4 15.5-68.6 27-94.7c10.5-23.6 22.2-40.7 33.5-51.5C239.4 3.2 248.7 0 256 0s16.6 3.2 27.8 13.8c11.3 10.8 23 27.9 33.5 51.5c11.6 26 20.9 58.2 27 94.7zm-209 0H18.6C48.6 85.9 112.2 29.1 190.6 8.4C165.1 42.6 145.3 96.1 135.3 160zM8.1 192C2.8 212.5 0 233.9 0 256s2.8 43.5 8.1 64H131.2c-2.1-20.6-3.2-42-3.2-64s1.1-43.4 3.2-64H8.1zM194.7 446.6c-11.6-26-20.9-58.2-27-94.6H344.3c-6.1 36.4-15.5 68.6-27 94.6c-10.5 23.6-22.2 40.7-33.5 51.5C272.6 508.8 263.3 512 256 512s-16.6-3.2-27.8-13.8c-11.3-10.8-23-27.9-33.5-51.5zM135.3 352c10 63.9 29.8 117.4 55.3 151.6C112.2 482.9 48.6 426.1 18.6 352H135.3zm358.1 0c-30 74.1-93.6 130.9-171.9 151.6c25.5-34.2 45.2-87.7 55.3-151.6H493.4z\"/\u003e\n\u003c/svg\u003e \n  \u003c/span\u003e\n\n Cloud-native architectures across major cloud providers\n\n\n  \u003cspan class=\"icon relative inline-block align-text-bottom\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 384 512\"\u003e\n  \u003cpath d=\"M16 64C16 28.7 44.7 0 80 0H304c35.3 0 64 28.7 64 64V448c0 35.3-28.7 64-64 64H80c-35.3 0-64-28.7-64-64V64zM224 448a32 32 0 1 0 -64 0 32 32 0 1 0 64 0zM304 64H80V384H304V64z\"/\u003e\n\u003c/svg\u003e \n  \u003c/span\u003e\n\n Distributed systems and microservices design\n\n\n  \u003cspan class=\"icon relative inline-block align-text-bottom\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 640 512\"\u003e\n  \u003cpath d=\"M96 224c35.3 0 64-28.7 64-64s-28.7-64-64-64S32 124.7 32 160s28.7 64 64 64zm448 0c35.3 0 64-28.7 64-64s-28.7-64-64-64s-64 28.7-64 64s28.7 64 64 64zm-32 32h-64c-17.6 0-33.8 5.8-46.8 15.4c-20.6-15.2-47.2-24.2-76.2-24.2c-29 0-55.6 9-76.2 24.2c-13-9.6-29.2-15.4-46.8-15.4h-64c-35.3 0-64 20.7-64 48v32c0 17.7 14.3 32 32 32h512c17.7 0 32-14.3 32-32v-32c0-27.3-28.7-48-64-48zm-256 0c-35.3 0-64-28.7-64-64s28.7-64 64-64s64 28.7 64 64s-28.7 64-64 64zm96 96H192c-17.7 0-32 14.3-32 32v32c0 17.7 14.3 32 32 32h256c17.7 0 32-14.3 32-32v-32c0-17.7-14.3-32-32-32z\"/\u003e\n\u003c/svg\u003e \n  \u003c/span\u003e\n\n Engineering leadership and team transformation\n\n\n  \u003cspan class=\"icon relative inline-block align-text-bottom\"\u003e\n    \u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 640 512\"\u003e\n  \u003cpath d=\"M278.9 511.5l-61-17.7c-6.5-1.8-10.1-8.6-8.3-15.1l21.7-82c-46.1-40.4-75-96.6-75-158.7C136 99.7 176.7 59 228 59c46.1 0 84.8 30.7 97.1 72.8c12.3-42.1 51-72.8 97.1-72.8c51.3 0 92 40.7 92 91c0 62.1-28.9 118.3-75 158.7l21.7 82c1.8 6.5-1.8 13.3-8.3 15.1l-61 17.7c-5.2 1.5-10.9-.5-13.5-4.9l-38.4-64.7c-3.7-6.2-12.6-6.2-16.3 0l-38.4 64.7c-2.6 4.4-8.3 6.4-13.5 4.9zM228 119c-30.9 0-56 25.1-56 56c0 30.9 25.1 56 56 56s56-25.1 56-56c0-30.9-25.1-56-56-56zm184 56c0-30.9-25.1-56-56-56s-56 25.1-56 56c0 30.9 25.1 56 56 56s56-25.1 56-56z\"/\u003e\n\u003c/svg\u003e \n  \u003c/span\u003e\n\n Multi-cloud platform engineering\u003c/p\u003e","title":"About"},{"content":"","date":null,"permalink":"/tags/development/","section":"Tags","summary":"","title":"Development"},{"content":"","date":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git"},{"content":" This article explores the importance of meaningful commit messages and provides practical guidelines for writing them effectively. Why Commit Messages Matter #Have you ever looked back at your Git history and wondered, \u0026ldquo;What on earth was I thinking when I made this change?\u0026rdquo; If so, you\u0026rsquo;re not alone. As developers, we\u0026rsquo;ve all been guilty of commit messages like \u0026ldquo;fix stuff\u0026rdquo; or \u0026ldquo;update code\u0026rdquo; at some point. These vague messages might seem harmless in the moment, but they create significant pain down the road.\nGood commit messages aren\u0026rsquo;t just a nicetyâ€”they\u0026rsquo;re a crucial form of documentation that serves multiple purposes:\nFuture-proofing your understanding: You might understand your changes today, but will you six months from now? Team communication: Clear messages help team members understand your intentions without having to ask. Debugging aid: When tracking down issues, meaningful commit messages can significantly speed up the process. Project history: They create a readable narrative of your project\u0026rsquo;s evolution. Examples of vague and clear commit messages Conventional Commits: A Structured Approach #One of the most effective approaches to commit messages is the Conventional Commits format. This specification provides a lightweight convention that creates a standardized and meaningful commit history.\nThe basic structure looks like this:\n\u0026lt;type\u0026gt;[optional scope]: \u0026lt;description\u0026gt; [optional body] [optional footer(s)] Common Types # feat: - A new feature for the user fix: - A bug fix docs: - Documentation only changes style: - Changes that don\u0026rsquo;t affect the meaning of the code (white-space, formatting, etc.) refactor: - Code change that neither fixes a bug nor adds a feature test: - Adding missing tests or correcting existing tests chore: - Changes to the build process or auxiliary tools and libraries Real-World Examples #Bad commit message:\ngit commit -m \u0026#34;fixed bug\u0026#34; Good commit message:\ngit commit -m \u0026#34;fix: prevent racing condition in user authentication flow\u0026#34; Even better with more details:\ngit commit -m \u0026#34;fix(auth): prevent racing condition in user authentication flow When multiple login attempts were made simultaneously from the same account, tokens could be incorrectly validated. This adds request locking to ensure consistent authentication state. Fixes #423\u0026#34; Beyond the Prefix: Writing the Content #While the prefix helps categorize the commit, the content of your message is where the real value lies. Here are some guidelines:\nBe specific but concise: Aim for a 50-72 character summary line. Use the imperative mood: Write as if you\u0026rsquo;re giving a command (e.g., \u0026ldquo;fix\u0026rdquo; not \u0026ldquo;fixed\u0026rdquo;). Explain the \u0026lsquo;why\u0026rsquo; not just the \u0026lsquo;what\u0026rsquo;: The code shows what changed; your message should explain why. Reference relevant issues: Include ticket numbers or issue IDs when applicable. Making It a Habit #Like any good practice, writing meaningful commit messages takes discipline. It might feel like extra work at first, but it quickly becomes second nature and pays dividends in the long run.\nConsider using tools like commitizen to help enforce this pattern, or set up Git hooks to validate commit message formats.\nConclusion #Your commit history is a first-class form of project documentation. Investing a few extra seconds to write clear, meaningful commit messages will save you and your teammates hours of confusion and detective work later.\nNext time you\u0026rsquo;re about to commit with a message like \u0026ldquo;updates\u0026rdquo; or \u0026ldquo;fixes,\u0026rdquo; take a moment to think about the developer (possibly future you) who will need to understand these changes later. Your future self will thank you.\n","date":"9 April 2025","permalink":"/posts/the-art-of-commit-messages/","section":"Posts","summary":"\u003cdiv class=\"flex rounded-md bg-primary-100 px-4 py-3 dark:bg-primary-900\"\u003e\n  \u003cspan class=\"pe-3 text-primary-400\"\u003e\n    \u003cspan class=\"icon relative inline-block px-1 align-text-bottom\"\u003e\u003csvg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"\u003e\u003cpath fill=\"currentColor\" d=\"M506.3 417l-213.3-364c-16.33-28-57.54-28-73.98 0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6C502.1 480 522.6 445 506.3 417zM232 168c0-13.25 10.75-24 24-24S280 154.8 280 168v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zM256 416c-17.36 0-31.44-14.08-31.44-31.44c0-17.36 14.07-31.44 31.44-31.44s31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z\"/\u003e\u003c/svg\u003e\n\u003c/span\u003e\n  \u003c/span\u003e\n  \u003cspan class=\"dark:text-neutral-300\"\u003eThis article explores the importance of meaningful commit messages and provides practical guidelines for writing them effectively.\u003c/span\u003e\n\u003c/div\u003e\n\n\u003ch2 id=\"why-commit-messages-matter\" class=\"relative group\"\u003eWhy Commit Messages Matter \u003cspan class=\"absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\"\u003e\u003ca class=\"group-hover:text-primary-300 dark:group-hover:text-neutral-700\" style=\"text-decoration-line: none !important;\" href=\"#why-commit-messages-matter\" aria-label=\"Anchor\"\u003e#\u003c/a\u003e\u003c/span\u003e\u003c/h2\u003e\u003cp\u003eHave you ever looked back at your Git history and wondered, \u0026ldquo;What on earth was I thinking when I made this change?\u0026rdquo; If so, you\u0026rsquo;re not alone. As developers, we\u0026rsquo;ve all been guilty of commit messages like \u0026ldquo;fix stuff\u0026rdquo; or \u0026ldquo;update code\u0026rdquo; at some point. These vague messages might seem harmless in the moment, but they create significant pain down the road.\u003c/p\u003e","title":"The Art of Meaningful Commit Messages"},{"content":"","date":"1 January 0001","permalink":"/archives/","section":"Nicholas Hammond","summary":"archives","title":"Archives"},{"content":"","date":"1 January 0001","permalink":"/search/","section":"Nicholas Hammond","summary":"search","title":"Search"}]